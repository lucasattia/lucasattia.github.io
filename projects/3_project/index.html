<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN" "http://www.w3.org/TR/REC-html40/loose.dtd"> <html><body> <p>Most of my thesis is motivated by poor aqueous solubility of hydrophobic drugs. However, organic solubility is also a crucial property, particularly for synethic/process chemistry and formulation processing. Measuring solubility accurately is extremely challenging, and experimental variability is high. Despite its importance, solubility is notoriously difficult to predict. There has been an enormous amount of work in making a good predictor for aqueous solubility (due to its relevance in drug function), and some tools have been quite successful. However, organic solubility has been comparatively neglected. We sought to create an accurate and accessible tool for the community to use.</p> <p>We used standard deep learning cheminformatics models (<a href="https://github.com/chemprop/chemprop" rel="external nofollow noopener" target="_blank">chemprop</a> and <a href="https://github.com/JacksonBurns/fastprop" rel="external nofollow noopener" target="_blank">fastprop</a>), and trained them on large datasets in the litetature. One cool training technique; we trained on the solubility loss and the loss of the gradient of solubility with respect to temperature (see equation below). This is a very general approach called <a href="https://arxiv.org/abs/1706.04859" rel="external nofollow noopener" target="_blank">Sobolev training</a>, which can be adapted for any DL problem where you care about the accuracy of the gradient of your target value with respect to an input (temperature, pH, concentration, etc).</p> \[\mathcal{L}(\hat S, S) = \frac{1}{n} \sum_{i=1}^n \left[ \left( \log S_i - \log \hat{S}_i \right)^2 + \alpha \left( \frac{d\, \log S_i}{d T_i} - \frac{d\, \log \hat{S}_i}{d T_i} \right)^2 \right].\] <p>The combination of this training approach, great model architectures, and compiled literature datasets gave us state-of-the-art performance. We rigorously show that our models achieve average accuracy that approaches the limit of experimental variability, the noise floor of the measurements themselves. Excitingly, our model (fastsolv) is quickly being adopted in industry, most notably by <a href="https://rowansci.com/tools/solubility" rel="external nofollow noopener" target="_blank">Rowan Scientific</a> (<a href="https://docs.rowansci.com/science/workflows/solubility" rel="external nofollow noopener" target="_blank">docs here</a>). We’ve also released an <a href="http://fastsolv.mit.edu/" rel="external nofollow noopener" target="_blank">open-source deployment of FastSolv</a>, making it accessible to the broader community for both research and practical applications.</p> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/fastsolv.PNG-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/fastsolv.PNG-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/fastsolv.PNG-1400.webp"></source> <img src="/assets/img/fastsolv.PNG" class="img-fluid rounded z-depth-1 mx-auto d-block" width="auto" height="auto" title="Solubility prediction" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <p>This project started as a class project in an <a href="https://computing.mit.edu/cross-cutting/common-ground-for-computing-education/common-ground-subjects/c01-c51-modeling-machine-learning/" rel="external nofollow noopener" target="_blank">MIT ML course</a>, so it’s been awesome to see it develop into a useful tool for the community.</p> </body></html>